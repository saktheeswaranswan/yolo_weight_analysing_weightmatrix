# -*- coding: utf-8 -*-
"""yolo-weight-analysing-weightmatrix.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10hTNTU1yNS1Pf2sRILSKXE6IKUbgPomV
"""

def create_polynomial(number):
    # Convert the number to a string to process it
    num_str = str(number)

    # Split the number into integer and fractional parts
    integer_part, fractional_part = num_str.split('.')

    # Determine the length of the fractional part
    fractional_length = len(fractional_part)

    # Create the polynomial with integer coefficients
    # Q(x) = 10^(len(fractional_part)) * x^(len(integer_part) + len(fractional_part)) - 1
    degree = len(integer_part) + fractional_length
    coefficient = 10 ** fractional_length

    # Create the polynomial representation
    polynomial = f"{coefficient} * x^{degree} - 1"

    return polynomial

# Given number
number = 12313.5425645743764532765486523865487235487523875487253874283756487523874283756472356485238787542387487235684723875487235487523875487235487523874582375487523875423587

# Generate the polynomial
polynomial = create_polynomial(number)
print("Polynomial with integer coefficients:", polynomial)

import numpy as np

# Coefficients of the polynomial 1000000000000 * x^17 - 1
coefficients = [1000000000000] + [0]*16 + [-1]

# Calculate the roots
roots = np.roots(coefficients)

# Print the roots
print("Roots of the polynomial 1000000000000 * x^17 - 1:")
for root in roots:
    print(root)

import numpy as np

# Given number
number = 12313.5425645743764532765486523865487235487523875487253874283756487523874283756472356485238787542387487235684723875487235487523875487235487523874582375487523875423587

# Convert the number to a string to process it
num_str = str(number)

# Split the number into integer and fractional parts
integer_part, fractional_part = num_str.split('.')

# Determine the degree of the polynomial
degree = len(integer_part) + len(fractional_part)

# Create the polynomial coefficients for 10^len(fractional_part) * x^degree - 1
coefficient = 10 ** len(fractional_part)
coefficients = [coefficient] + [0] * (degree - 1) + [-1]

# Calculate the roots
roots = np.roots(coefficients)

# Print the roots
print("Roots of the polynomial with the given number as a root:")
for root in roots:
    print(root)

import numpy as np

def read_yolo_weights(file_path):
    with open(file_path, 'rb') as f:
        # Skip the header
        header = f.read(4 * 5)  # 5 integers
        weights = np.fromfile(f, dtype=np.float32)  # Read the rest as floats
    return weights

def main():
    file_path = '/content/yolov3-tiny.weights'  # Path to your weights file
    weights = read_yolo_weights(file_path)

    # Reshape or convert to a 2D array for easier viewing
    # For demonstration, let's display the first 10 weights as a flat matrix
    print(weights[:10])  # Adjust the slice as needed for more weights

    # If you want to visualize it as a 2D matrix:
    matrix_shape = (1, -1)  # You can adjust the shape as needed
    weights_matrix = weights.reshape(matrix_shape)

    print(weights_matrix)

if __name__ == '__main__':
    main()

import numpy as np

def read_yolo_weights(file_path):
    with open(file_path, 'rb') as f:
        # Skip the header
        header = f.read(4 * 5)  # Skip 5 integers in the header
        weights = np.fromfile(f, dtype=np.float32)  # Read weights
    return weights

def main():
    file_path = '/content/yolov3-tiny.weights'  # Path to your weights file
    weights = read_yolo_weights(file_path)

    # Print the total number of weights
    print(f'Total number of weights: {weights.size}')

    # Reshape weights to a 2D matrix; you can adjust dimensions based on your requirements
    # For demonstration, let's use a shape of (number_of_layers, weights_per_layer)
    # This will need to be tailored based on YOLO's architecture
    num_layers = 9  # Example number of layers in YOLOv3-tiny; adjust as needed
    weights_per_layer = weights.size // num_layers  # Calculate weights per layer

    # Check if the weights can be evenly divided
    if weights.size % num_layers != 0:
        raise ValueError("Weights cannot be evenly divided into layers.")

    weights_matrix = weights.reshape(num_layers, weights_per_layer)

    # Print the entire matrix
    print(weights_matrix)

if __name__ == '__main__':
    main()

import numpy as np

def read_yolo_weights(file_path):
    with open(file_path, 'rb') as f:
        header = f.read(4 * 5)  # Skip the header
        weights = np.fromfile(f, dtype=np.float32)  # Read weights
    return weights

def get_layer_shapes():
    # Define the shapes for each layer in YOLOv3-tiny
    layer_shapes = [
        (3 * 3 * 3 * 16, 'conv1'),     # Conv Layer 1
        (3 * 3 * 16 * 32, 'conv2'),    # Conv Layer 2
        (3 * 3 * 32 * 64, 'conv3'),     # Conv Layer 3
        (3 * 3 * 64 * 128, 'conv4'),    # Conv Layer 4
        (3 * 3 * 128 * 256, 'conv5'),   # Conv Layer 5
        (3 * 3 * 256 * 512, 'conv6'),   # Conv Layer 6
        (3 * 3 * 512 * 1024, 'conv7'),  # Conv Layer 7
        (1 * 1 * 512 * 256, 'conv8'),    # Conv Layer 8
        (3 * 3 * 256 * 512, 'conv9'),    # Conv Layer 9
        (1 * 1 * 512 * 255, 'conv10'),   # Conv Layer 10 (final layer before YOLO)
    ]
    return layer_shapes

def main():
    file_path = 'yolov3-tiny.weights'  # Path to your weights file
    weights = read_yolo_weights(file_path)

    layer_shapes = get_layer_shapes()
    index = 0

    for shape, layer_name in layer_shapes:
        layer_weights = weights[index:index + shape].reshape(-1)
        index += shape

        # Print weights for the layer
        print(f"Weights for {layer_name}:")
        print(layer_weights)
        print()  # Newline for better readability

if __name__ == '__main__':
    main()

import numpy as np
import matplotlib.pyplot as plt
import networkx as nx

def read_yolo_weights(file_path):
    with open(file_path, 'rb') as f:
        header = f.read(4 * 5)  # Skip the header
        weights = np.fromfile(f, dtype=np.float32)  # Read weights
    return weights

def get_layer_shapes():
    # Define the shapes for each layer in YOLOv3-tiny
    layer_shapes = [
        (3 * 3 * 3 * 16, 'conv1'),     # Conv Layer 1
        (3 * 3 * 16 * 32, 'conv2'),    # Conv Layer 2
        (3 * 3 * 32 * 64, 'conv3'),     # Conv Layer 3
        (3 * 3 * 64 * 128, 'conv4'),    # Conv Layer 4
        (3 * 3 * 128 * 256, 'conv5'),   # Conv Layer 5
        (3 * 3 * 256 * 512, 'conv6'),   # Conv Layer 6
        (3 * 3 * 512 * 1024, 'conv7'),  # Conv Layer 7
        (1 * 1 * 512 * 256, 'conv8'),    # Conv Layer 8
        (3 * 3 * 256 * 512, 'conv9'),    # Conv Layer 9
        (1 * 1 * 512 * 255, 'conv10'),   # Conv Layer 10 (final layer before YOLO)
    ]
    return layer_shapes

def plot_network(layer_shapes, weights):
    G = nx.DiGraph()

    index = 0
    for shape, layer_name in layer_shapes:
        layer_weights = weights[index:index + shape].reshape(-1)
        index += shape

        # Add layer to the graph
        G.add_node(layer_name, weight=np.mean(layer_weights))  # Store mean weight for visualization

        # Connect layers (simple sequential connection)
        if index > shape:
            G.add_edge(layer_shapes[layer_shapes.index((shape, layer_name)) - 1][1], layer_name)

    pos = nx.spring_layout(G)  # positions for all nodes
    weights = [G.nodes[node]['weight'] for node in G.nodes]  # Retrieve weights for coloring

    # Draw the graph
    nx.draw(G, pos, with_labels=True, node_size=3000, node_color=weights, cmap=plt.cm.Blues, font_size=10)
    plt.title('YOLOv3-Tiny Neural Network Architecture')
    plt.colorbar(plt.cm.ScalarMappable(cmap=plt.cm.Blues), label='Mean Weight')
    plt.show()

def main():
    file_path = 'yolov3-tiny.weights'  # Path to your weights file
    weights = read_yolo_weights(file_path)

    layer_shapes = get_layer_shapes()
    plot_network(layer_shapes, weights)

if __name__ == '__main__':
    main()

import numpy as np

def read_rnn_weights(file_path):
    with open(file_path, 'rb') as f:
        # Skip the header (assuming standard header size for RNNs)
        header = f.read(4 * 5)  # Adjust if necessary for your specific weights file
        weights = np.fromfile(f, dtype=np.float32)  # Read weights
    return weights

def get_layer_shapes():
    # Define the expected shapes for each layer in the RNN
    layer_shapes = [
        (1024 * 1024, 'rnn_layer1'),  # RNN Layer 1 weights
        (1024 * 1024, 'rnn_layer2'),  # RNN Layer 2 weights
        (1024 * 1024, 'rnn_layer3'),  # RNN Layer 3 weights
        (1024 * 256, 'connected_layer'),  # Connected Layer weights
    ]
    return layer_shapes

def main():
    file_path = '/content/shakespeare.weights'  # Path to your weights file
    weights = read_rnn_weights(file_path)

    layer_shapes = get_layer_shapes()
    index = 0

    for shape, layer_name in layer_shapes:
        layer_weights = weights[index:index + shape].reshape(-1)
        index += shape

        # Print weights for the layer as a matrix
        print(f"Weights for {layer_name}:")
        print(layer_weights)
        print()  # Newline for better readability

if __name__ == '__main__':
    main()

import numpy as np
import matplotlib.pyplot as plt

def read_rnn_weights(file_path):
    with open(file_path, 'rb') as f:
        header = f.read(4 * 5)  # Adjust if necessary for your specific weights file
        weights = np.fromfile(f, dtype=np.float32)  # Read weights
    return weights

def get_layer_shapes():
    # Define the expected shapes for each layer in the RNN
    layer_shapes = [
        (1024 * 1024, 'rnn_layer1'),  # RNN Layer 1 weights
        (1024 * 1024, 'rnn_layer2'),  # RNN Layer 2 weights
        (1024 * 1024, 'rnn_layer3'),  # RNN Layer 3 weights
        (1024 * 256, 'connected_layer'),  # Connected Layer weights
    ]
    return layer_shapes

def plot_weights(weights):
    fig, ax = plt.subplots(figsize=(12, 8))
    heatmap = ax.imshow(weights, aspect='auto', cmap='viridis')

    # Add colorbar for reference
    plt.colorbar(heatmap)

    ax.set_title('RNN Weights Visualization')
    ax.set_xlabel('Weight Index')
    ax.set_ylabel('Layers')

    plt.show()

def main():
    file_path = '/content/shakespeare.weights'  # Path to your uploaded weights file
    weights = read_rnn_weights(file_path)

    layer_shapes = get_layer_shapes()
    index = 0
    all_weights = []

    for shape, layer_name in layer_shapes:
        layer_weights = weights[index:index + shape].reshape(-1)
        index += shape

        # Add the weights to a combined list
        all_weights.append(layer_weights)

    # Combine all weights into a single 2D array for visualization
    combined_weights = np.concatenate(all_weights).reshape(len(layer_shapes), -1)

    # Plotting the combined weights
    plot_weights(combined_weights)

if __name__ == '__main__':
    main()

import numpy as np
import matplotlib.pyplot as plt

# Generate synthetic data
def generate_data(seq_length=10, num_samples=1000):
    X = np.random.randn(num_samples, seq_length)
    y = np.sum(X, axis=1)  # Target is the sum of the sequence
    return X, y

# Simple RNN implementation
class SimpleRNN:
    def __init__(self, input_size, hidden_size):
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01  # Input to hidden
        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01  # Hidden to hidden
        self.bh = np.zeros((hidden_size, 1))  # Hidden bias

    def forward(self, inputs):
        h = np.zeros((self.hidden_size, 1))
        for x in inputs:
            h = np.tanh(np.dot(self.Wxh, x) + np.dot(self.Whh, h) + self.bh)
        return h

    def compute_gradients(self, inputs, target):
        h = np.zeros((self.hidden_size, 1))
        gradients = []
        loss = 0

        for x in inputs:
            h = np.tanh(np.dot(self.Wxh, x) + np.dot(self.Whh, h) + self.bh)
            gradients.append(h)  # Store gradients for visualization

        # Example of loss (MSE)
        loss = (target - h) ** 2
        return gradients, loss

    def clip_gradients(self, gradients, clip_value=1.0):
        # Clip gradients to prevent exploding gradients
        clipped_gradients = [np.clip(g, -clip_value, clip_value) for g in gradients]
        return clipped_gradients

# Training
input_size = 1
hidden_size = 5
rnn = SimpleRNN(input_size, hidden_size)

# Generate data
X, y = generate_data()

# Collect gradients for visualization
all_gradients = []
for i in range(len(X)):
    gradients, _ = rnn.compute_gradients(X[i].reshape(-1, 1), y[i])
    # Clip the gradients
    clipped_gradients = rnn.clip_gradients(gradients)

    # Print clipped gradient for each layer
    for j, grad in enumerate(clipped_gradients):
        print(f'Clipped Gradient for layer {j+1} at sample {i}:')
        print(grad.flatten())
        print()  # Newline for better readability

    all_gradients.append(np.array(clipped_gradients).flatten())

# Convert to array for visualization
all_gradients = np.array(all_gradients)

# Plotting the gradients
plt.figure(figsize=(12, 6))
plt.imshow(all_gradients, aspect='auto', cmap='viridis')
plt.colorbar(label='Gradient Value')
plt.title('Clipped Gradients in RNN over Time Steps')
plt.xlabel('Time Steps')
plt.ylabel('Sample Index')
plt.show()

import numpy as np

def read_yolo_weights(file_path):
    with open(file_path, 'rb') as f:
        # Skip the header (assuming standard YOLO format)
        header = f.read(4 * 5)  # Adjust if necessary
        weights = np.fromfile(f, dtype=np.float32)  # Read weights
    return weights

def parse_cfg(file_path):
    layers = []
    with open(file_path, 'r') as f:
        for line in f:
            if line.startswith('['):
                layer_type = line.strip()[1:-1]
                layers.append({'type': layer_type})
            elif '=' in line:
                key, value = line.strip().split('=')
                layers[-1][key] = value.strip()
    return layers

def extract_weights(weights, layers):
    index = 0
    layer_weights = {}

    for layer in layers:
        layer_type = layer['type']
        if layer_type == 'convolutional':
            filters = int(layer['filters'])
            size = int(layer['size'])
            in_channels = int(layer.get('channels', 3))  # Default to 3 if not defined
            weights_shape = (filters, in_channels, size, size)
            layer_weights[layer_type] = weights[index:index + np.prod(weights_shape)].reshape(weights_shape)
            index += np.prod(weights_shape)
            # Skip biases
            layer_weights[layer_type + '_bias'] = weights[index:index + filters]
            index += filters
        elif layer_type == 'connected':
            output = int(layer['output'])
            layer_weights[layer_type] = weights[index:index + output]
            index += output
        elif layer_type == 'batch_normalize':
            layer_weights[layer_type] = weights[index:index + 4 * filters]
            index += 4 * filters

    return layer_weights

def print_weights(layer_weights):
    for layer_name, weight_matrix in layer_weights.items():
        if 'bias' not in layer_name:  # Skip biases for printing
            print(f'Weights for {layer_name}:')
            print(weight_matrix)
            print()  # Newline for better readability

def main():
    weights_file_path = '/content/yolov3-tiny.weights'  # Path to your weights file
    cfg_file_path = '/content/yolov3-tiny (1).cfg'  # Path to your cfg file

    weights = read_yolo_weights(weights_file_path)
    layers = parse_cfg(cfg_file_path)
    layer_weights = extract_weights(weights, layers)

    # Print the weights
    print_weights(layer_weights)

if __name__ == '__main__':
    main()

import numpy as np

def read_rnn_weights(file_path):
    with open(file_path, 'rb') as f:
        weights = np.fromfile(f, dtype=np.float32)  # Read weights
    return weights

def parse_cfg(file_path):
    layers = []
    with open(file_path, 'r') as f:
        for line in f:
            if line.startswith('['):
                layer_type = line.strip()[1:-1]
                layers.append({'type': layer_type})
            elif '=' in line:
                key, value = line.strip().split('=')
                layers[-1][key.strip()] = value.strip()
    return layers

def extract_weights(weights, layers):
    index = 0
    layer_weights = {}

    for layer in layers:
        layer_type = layer['type']
        if layer_type == 'rnn':
            output = int(layer.get('output', 1024))  # Default if not specified
            hidden = int(layer.get('hidden', 1024))  # Default if not specified
            layer_weights[layer_type] = weights[index:index + output * hidden].reshape(output, hidden)
            index += output * hidden
            layer_weights[layer_type + '_bias'] = weights[index:index + output]
            index += output
        elif layer_type == 'connected':
            output = int(layer['output'])
            layer_weights[layer_type] = weights[index:index + output]
            index += output

    return layer_weights

def print_weights(layer_weights):
    for layer_name, weight_matrix in layer_weights.items():
        if 'bias' not in layer_name:  # Skip biases for printing
            print(f'Weights for {layer_name}:')
            print(weight_matrix)
            print()  # Newline for better readability

def main():
    weights_file_path = '/content/shakespeare.weights'  # Path to your weights file
    cfg_file_path = '/content/rnn.cfg'  # Path to your cfg file

    weights = read_rnn_weights(weights_file_path)
    layers = parse_cfg(cfg_file_path)
    layer_weights = extract_weights(weights, layers)

    # Print the weights
    print_weights(layer_weights)

if __name__ == '__main__':
    main()

import numpy as np

def read_rnn_weights(file_path):
    with open(file_path, 'rb') as f:
        weights = np.fromfile(f, dtype=np.float32)  # Read weights
    return weights

def parse_cfg(file_path):
    layers = []
    with open(file_path, 'r') as f:
        for line in f:
            if line.startswith('['):
                layer_type = line.strip()[1:-1]
                layers.append({'type': layer_type})
            elif '=' in line:
                key, value = line.strip().split('=')
                layers[-1][key.strip()] = value.strip()
    return layers

def extract_weights(weights, layers):
    index = 0
    layer_weights = {}

    for layer in layers:
        layer_type = layer['type']
        if layer_type == 'rnn':
            output = int(layer.get('output', 1024))  # Default if not specified
            hidden = int(layer.get('hidden', 1024))  # Default if not specified
            layer_weights[layer_type] = weights[index:index + output * hidden].reshape(output, hidden)
            index += output * hidden
            layer_weights[layer_type + '_bias'] = weights[index:index + output]
            index += output
        elif layer_type == 'connected':
            output = int(layer['output'])
            layer_weights[layer_type] = weights[index:index + output]
            index += output

    return layer_weights

def clip_weights(layer_weights, clip_value):
    """Clip the weights of each layer to prevent exploding gradients."""
    for layer_name, weight_matrix in layer_weights.items():
        layer_weights[layer_name] = np.clip(weight_matrix, -clip_value, clip_value)
    return layer_weights

def print_weights(layer_weights):
    for layer_name, weight_matrix in layer_weights.items():
        if 'bias' not in layer_name:  # Skip biases for printing
            print(f'Weights for {layer_name}:')
            print(weight_matrix)
            print()  # Newline for better readability

def main():
    weights_file_path = '/content/shakespeare.weights'  # Path to your weights file
    cfg_file_path = '/content/rnn.cfg'  # Path to your cfg file
    clip_value = 1.0  # Set your clipping threshold

    weights = read_rnn_weights(weights_file_path)
    layers = parse_cfg(cfg_file_path)
    layer_weights = extract_weights(weights, layers)

    # Clip the weights
    clipped_weights = clip_weights(layer_weights, clip_value)

    # Print the clipped weights
    print_weights(clipped_weights)

if __name__ == '__main__':
    main()

import numpy as np

def read_rnn_weights(file_path):
    """Read weights from the specified file."""
    with open(file_path, 'rb') as f:
        weights = np.fromfile(f, dtype=np.float32)  # Read weights
    return weights

def parse_cfg(file_path):
    """Parse the configuration file to extract layer information."""
    layers = []
    with open(file_path, 'r') as f:
        for line in f:
            if line.startswith('['):
                layer_type = line.strip()[1:-1]
                layers.append({'type': layer_type})
            elif '=' in line:
                key, value = line.strip().split('=')
                layers[-1][key.strip()] = value.strip()
    return layers

def extract_weights(weights, layers):
    """Extract weights based on the parsed configuration."""
    index = 0
    layer_weights = {}

    for layer in layers:
        layer_type = layer['type']
        if layer_type == 'rnn':
            output = int(layer.get('output', 1024))
            hidden = int(layer.get('hidden', 1024))
            layer_weights[layer_type] = weights[index:index + output * hidden].reshape(output, hidden)
            index += output * hidden
            layer_weights[layer_type + '_bias'] = weights[index:index + output]
            index += output
        elif layer_type == 'connected':
            output = int(layer['output'])
            layer_weights[layer_type] = weights[index:index + output]
            index += output

    return layer_weights

def clip_weights(layer_weights, clip_value):
    """Clip the weights to prevent exploding gradients."""
    for layer_name, weight_matrix in layer_weights.items():
        layer_weights[layer_name] = np.clip(weight_matrix, -clip_value, clip_value)
    return layer_weights

def apply_regularization(weights, reg_type='L2', lambda_reg=0.01):
    """Apply regularization techniques to the weights."""
    if reg_type == 'L2':
        for layer_name, weight_matrix in weights.items():
            weights[layer_name] = weight_matrix * (1 - lambda_reg)
    return weights

def print_weights(layer_weights):
    """Print the weights of each layer."""
    for layer_name, weight_matrix in layer_weights.items():
        if 'bias' not in layer_name:  # Skip biases for printing
            print(f'Weights for {layer_name}:')
            print(weight_matrix)
            print()  # Newline for better readability

def main():
    weights_file_path = '/content/shakespeare.weights'  # Path to your weights file
    cfg_file_path = '/content/rnn.cfg'  # Path to your cfg file
    clip_value = 1.0  # Clipping threshold for weights
    lambda_reg = 0.01  # Regularization strength

    # Read and process weights
    weights = read_rnn_weights(weights_file_path)
    layers = parse_cfg(cfg_file_path)
    layer_weights = extract_weights(weights, layers)

    # Clip the weights to mitigate exploding gradients
    clipped_weights = clip_weights(layer_weights, clip_value)

    # Apply L2 regularization to prevent overfitting
    regularized_weights = apply_regularization(clipped_weights, 'L2', lambda_reg)

    # Print the final weights
    print_weights(regularized_weights)

if __name__ == '__main__':
    main()

import numpy as np

def read_rnn_weights(file_path):
    """Read weights from the specified file."""
    with open(file_path, 'rb') as f:
        weights = np.fromfile(f, dtype=np.float32)  # Read weights
    return weights

def parse_cfg(file_path):
    """Parse the configuration file to extract layer information."""
    layers = []
    with open(file_path, 'r') as f:
        for line in f:
            if line.startswith('['):
                layer_type = line.strip()[1:-1]
                layers.append({'type': layer_type})
            elif '=' in line:
                key, value = line.strip().split('=')
                layers[-1][key.strip()] = value.strip()
    return layers

def extract_weights(weights, layers):
    """Extract weights based on the parsed configuration."""
    index = 0
    layer_weights = {}

    for layer in layers:
        layer_type = layer['type']
        if layer_type == 'rnn':
            output = int(layer.get('output', 1024))
            hidden = int(layer.get('hidden', 1024))
            layer_weights[layer_type] = weights[index:index + output * hidden].reshape(output, hidden)
            index += output * hidden
            layer_weights[layer_type + '_bias'] = weights[index:index + output]
            index += output
        elif layer_type == 'connected':
            output = int(layer['output'])
            layer_weights[layer_type] = weights[index:index + output]
            index += output

    return layer_weights

def random_initialize_weights(layer_weights, scale=0.01):
    """Randomly initialize weights using a small scale."""
    for layer_name in layer_weights:
        if 'bias' not in layer_name:  # Skip biases for initialization
            layer_weights[layer_name] = np.random.randn(*layer_weights[layer_name].shape) * scale
    return layer_weights

def normalize_weights(layer_weights):
    """Normalize the weights of each layer to have zero mean and unit variance."""
    for layer_name, weight_matrix in layer_weights.items():
        if 'bias' not in layer_name:  # Skip biases for normalization
            mean = np.mean(weight_matrix)
            std = np.std(weight_matrix)
            layer_weights[layer_name] = (weight_matrix - mean) / (std + 1e-8)  # Avoid division by zero
    return layer_weights

def clip_weights(layer_weights, clip_value):
    """Clip the weights to prevent exploding gradients."""
    for layer_name, weight_matrix in layer_weights.items():
        layer_weights[layer_name] = np.clip(weight_matrix, -clip_value, clip_value)
    return layer_weights

def apply_regularization(weights, reg_type='L2', lambda_reg=0.01):
    """Apply regularization techniques to the weights."""
    if reg_type == 'L2':
        for layer_name, weight_matrix in weights.items():
            weights[layer_name] = weight_matrix * (1 - lambda_reg)
    return weights

def print_weights(layer_weights):
    """Print the weights of each layer."""
    for layer_name, weight_matrix in layer_weights.items():
        if 'bias' not in layer_name:  # Skip biases for printing
            print(f'Weights for {layer_name}:')
            print(weight_matrix)
            print()  # Newline for better readability

def main():
    weights_file_path = '/content/shakespeare.weights'  # Path to your weights file
    cfg_file_path = '/content/rnn.cfg'  # Path to your cfg file
    clip_value = 1.0  # Clipping threshold for weights
    lambda_reg = 0.01  # Regularization strength

    # Read and process weights
    weights = read_rnn_weights(weights_file_path)
    layers = parse_cfg(cfg_file_path)
    layer_weights = extract_weights(weights, layers)

    # Randomly initialize weights
    initialized_weights = random_initialize_weights(layer_weights)

    # Normalize the weights
    normalized_weights = normalize_weights(initialized_weights)

    # Clip the weights to mitigate exploding gradients
    clipped_weights = clip_weights(normalized_weights, clip_value)

    # Apply L2 regularization to prevent overfitting
    regularized_weights = apply_regularization(clipped_weights, 'L2', lambda_reg)

    # Print the final weights
    print_weights(regularized_weights)

if __name__ == '__main__':
    main()

import numpy as np

def read_rnn_weights(file_path):
    """Read weights from the specified file."""
    with open(file_path, 'rb') as f:
        weights = np.fromfile(f, dtype=np.float32)  # Read weights
    return weights

def parse_cfg(file_path):
    """Parse the configuration file to extract layer information."""
    layers = []
    with open(file_path, 'r') as f:
        for line in f:
            if line.startswith('['):
                layer_type = line.strip()[1:-1]
                layers.append({'type': layer_type})
            elif '=' in line:
                key, value = line.strip().split('=')
                layers[-1][key.strip()] = value.strip()
    return layers

def extract_weights(weights, layers):
    """Extract weights based on the parsed configuration."""
    index = 0
    layer_weights = {}

    for layer in layers:
        layer_type = layer['type']
        if layer_type == 'rnn':
            output = int(layer.get('output', 1024))
            hidden = int(layer.get('hidden', 1024))
            layer_weights[layer_type] = weights[index:index + output * hidden].reshape(output, hidden)
            index += output * hidden
            layer_weights[layer_type + '_bias'] = weights[index:index + output]
            index += output
        elif layer_type == 'connected':
            output = int(layer['output'])
            layer_weights[layer_type] = weights[index:index + output]
            index += output

    return layer_weights

def random_initialize_weights(layer_weights, scale=0.01):
    """Randomly initialize weights using a small scale."""
    for layer_name in layer_weights:
        if 'bias' not in layer_name:  # Skip biases for initialization
            layer_weights[layer_name] = np.random.randn(*layer_weights[layer_name].shape) * scale
    return layer_weights

def normalize_weights(layer_weights):
    """Normalize the weights of each layer to have zero mean and unit variance."""
    for layer_name, weight_matrix in layer_weights.items():
        if 'bias' not in layer_name:  # Skip biases for normalization
            mean = np.mean(weight_matrix)
            std = np.std(weight_matrix)
            layer_weights[layer_name] = (weight_matrix - mean) / (std + 1e-8)  # Avoid division by zero
    return layer_weights

def clip_weights(layer_weights, clip_value):
    """Clip the weights to prevent exploding gradients."""
    for layer_name, weight_matrix in layer_weights.items():
        layer_weights[layer_name] = np.clip(weight_matrix, -clip_value, clip_value)
    return layer_weights

def apply_regularization(weights, reg_type='L2', lambda_reg=0.01):
    """Apply regularization techniques to the weights."""
    if reg_type == 'L2':
        for layer_name, weight_matrix in weights.items():
            weights[layer_name] = weight_matrix * (1 - lambda_reg)
    return weights

def learning_rate_schedule(initial_lr, epoch, drop_factor=0.5, drop_epoch=10):
    """Adjust learning rate based on the epoch."""
    if epoch % drop_epoch == 0:
        return initial_lr * drop_factor
    return initial_lr

def print_weights(layer_weights):
    """Print the weights of each layer."""
    for layer_name, weight_matrix in layer_weights.items():
        if 'bias' not in layer_name:  # Skip biases for printing
            print(f'Weights for {layer_name}:')
            print(weight_matrix)
            print()  # Newline for better readability

def main():
    weights_file_path = '/content/shakespeare.weights'  # Path to your weights file
    cfg_file_path = '/content/rnn.cfg'  # Path to your cfg file
    clip_value = 1.0  # Clipping threshold for weights
    lambda_reg = 0.01  # Regularization strength
    initial_lr = 0.1  # Initial learning rate

    # Read and process weights
    weights = read_rnn_weights(weights_file_path)
    layers = parse_cfg(cfg_file_path)
    layer_weights = extract_weights(weights, layers)

    # Randomly initialize weights
    initialized_weights = random_initialize_weights(layer_weights)

    # Normalize the weights
    normalized_weights = normalize_weights(initialized_weights)

    # Clip the weights to mitigate exploding gradients
    clipped_weights = clip_weights(normalized_weights, clip_value)

    # Apply L2 regularization to prevent overfitting
    regularized_weights = apply_regularization(clipped_weights, 'L2', lambda_reg)

    # Print the final weights
    print_weights(regularized_weights)

    # Example of using learning rate scheduling
    for epoch in range(1, 21):  # Simulate 20 epochs
        lr = learning_rate_schedule(initial_lr, epoch)
        print(f'Epoch {epoch}, Learning Rate: {lr}')

if __name__ == '__main__':
    main()